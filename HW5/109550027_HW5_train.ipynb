{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models,transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from captcha.image import ImageCaptcha\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"train\"\n",
    "TEST_PATH = \"test\"\n",
    "BATCH = 50\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# try device = \"cuda\" \n",
    "# and change your settings/accelerator to GPU if you want it to run faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "NUM_ALPHA = NUMBER + ALPHABET\n",
    "def encode(label):\n",
    "    ohlabel = []\n",
    "    for l in label:\n",
    "        oh = [0]*len(NUM_ALPHA)\n",
    "        idx = NUM_ALPHA.index(l)\n",
    "        oh[idx] = 1\n",
    "        ohlabel += oh\n",
    "    #print(label)\n",
    "    #print(ohlabel)\n",
    "    return np.array(ohlabel)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from captcha.image import ImageCaptcha\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport random\\n\\nimport string\\n\\nwidth, height, n_len, n_class = 72, 72, 2, len(NUM_ALPHA)\\nfor i in range(5000):\\n    generator = ImageCaptcha(width=width, height=height)\\n    random_str = \\'\\'.join([random.choice(NUM_ALPHA) for j in range(n_len)])\\n    img = generator.generate_image(random_str)\\n\\n    with open(\\'./train/annotations.csv\\', \\'a\\', newline=\\'\\') as csvfile:\\n        csv_writer = csv.writer(csvfile)\\n        csv_writer.writerow([f\"task2/moretrain{i}.png\", random_str])\\n    img.save(f\"./train/task2/moretrain{i}.png\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate data for task3\n",
    "def gen_train_data(width, height, n_len, task):\n",
    "    n_class = len(NUM_ALPHA)\n",
    "    for i in range(5000):\n",
    "        generator = ImageCaptcha(width=width, height=height)\n",
    "        random_str = ''.join([random.choice(NUM_ALPHA) for j in range(n_len)])\n",
    "        img = generator.generate_image(random_str)\n",
    "\n",
    "        with open('./train/annotations.csv', 'a', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow([f\"task{task}/moretrain{i}.png\", random_str])\n",
    "        img.save(f\"./train/task{task}/moretrain{i}.png\")\n",
    "\n",
    "#gen_train_data(72, 72, 2, 2)\n",
    "#gen_train_data(96, 72, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task1Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False):\n",
    "        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        self.captchalen = 1\n",
    "        self.h = None\n",
    "        self.w = None\n",
    "        self.c = 3\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        img = cv2.imread(f\"{self.root}/{filename}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        h, w= img.shape\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        #img = cv2.resize(img, (512,512))\n",
    "        #img = np.mean(img, axis=2)\n",
    "        #print(img.shape)\n",
    "        if self.return_filename:\n",
    "            return torch.FloatTensor(img), filename\n",
    "        else:\n",
    "            return torch.FloatTensor(img), encode(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task2Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False):\n",
    "        self.data = [sample for sample in data if sample[0].startswith(\"task2\")]\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        self.captchalen = 2\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        img = cv2.imread(f\"{self.root}/{filename}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        h, w= img.shape\n",
    "        img = cv2.resize(img, (72,72))\n",
    "        #img = np.mean(img, axis=2)\n",
    "        #imgplot = plt.imshow(img)\n",
    "        #plt.show()\n",
    "        if self.return_filename:\n",
    "            return torch.FloatTensor(img), filename\n",
    "        else:\n",
    "            return torch.FloatTensor(img), encode(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task3Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False):\n",
    "        self.data = [sample for sample in data if sample[0].startswith(\"task3\")]\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        self.captchalen = 4\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        img = cv2.imread(f\"{self.root}/{filename}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        h, w= img.shape\n",
    "        #print(h,w) 72 96\n",
    "        #img = cv2.resize(img, (32, 32))\n",
    "        #img = np.mean(img, axis=2)\n",
    "        #imgplot = plt.imshow(img)\n",
    "        #plt.show()\n",
    "        if self.return_filename:\n",
    "            return torch.FloatTensor(img), filename\n",
    "        else:\n",
    "            return torch.FloatTensor(img), encode(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        if random.random() < 0.7:\n",
    "            train_data.append(row)\n",
    "        else:\n",
    "            val_data.append(row)\n",
    "\n",
    "train_ds = Task1Dataset(train_data, root=TRAIN_PATH)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH, num_workers=0, drop_last=True, shuffle=True)\n",
    "val_ds = Task1Dataset(val_data, root=TRAIN_PATH)\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH, num_workers=0, drop_last=False, shuffle=False)\n",
    "\n",
    "train2_ds = Task2Dataset(train_data, root=TRAIN_PATH)\n",
    "train2_dl = DataLoader(train2_ds, batch_size=BATCH, num_workers=0, drop_last=True, shuffle=True)\n",
    "val2_ds = Task2Dataset(val_data, root=TRAIN_PATH)\n",
    "val2_dl = DataLoader(val2_ds, batch_size=BATCH, num_workers=0, drop_last=False, shuffle=False)\n",
    "\n",
    "train3_ds = Task3Dataset(train_data, root=TRAIN_PATH)\n",
    "train3_dl = DataLoader(train3_ds, batch_size=BATCH, num_workers=0, drop_last=True, shuffle=True)\n",
    "val3_ds = Task3Dataset(val_data, root=TRAIN_PATH)\n",
    "val3_dl = DataLoader(val3_ds, batch_size=BATCH, num_workers=0, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, OUTPUT_LEN, TEMP_OUT):\n",
    "        super().__init__()\n",
    "        self.OUTPUT_LEN = OUTPUT_LEN\n",
    "        self.TEMP_OUT = TEMP_OUT\n",
    "        self.conv1 = nn.Sequential(\n",
    "            #nn.Conv2d(1, 3, kernel_size=3),\n",
    "            nn.Conv2d(1, 8, kernel_size=3),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(8, 16, kernel_size=3),\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(16, 128, kernel_size=5),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, kernel_size=3),\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3),\n",
    "            nn.Conv2d(512, 512, kernel_size=3),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # convolutional layer (sees 30*30*3 tensor)\n",
    "        # linear layer (28*28*3 -> 100)\n",
    "        self.fc1 = nn.Linear(TEMP_OUT, 500)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        # linear layer (100 -> 10)\n",
    "        self.fc2 = nn.Linear(500, self.OUTPUT_LEN)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        batch, height, width = x.shape\n",
    "        x = x.view(batch, 1, height, width)\n",
    "        #print(x.size())\n",
    "        # sequance of convolutional layers with relu activation\n",
    "        x = self.conv1(x)\n",
    "        #print(x.size())\n",
    "        x = self.conv2(x)\n",
    "        #x = self.drop(x)\n",
    "        #print(x.size())\n",
    "        x = self.conv3(x)\n",
    "        x = self.drop(x)\n",
    "        #print(x.size())\n",
    "        #x = self.conv4(x)\n",
    "        # flatten the image input\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, self.TEMP_OUT)\n",
    "        # 1st hidden layer with relu activation\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # output-layer\n",
    "        #print(x.size())\n",
    "        \n",
    "        #print(x.size())\n",
    "        x = self.fc2(x)\n",
    "        #print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dl, val_dl, train_ds, epochs=80, TEMP_OUT=4096):\n",
    "    task = train_ds.captchalen\n",
    "    OUTPUT_LEN = len(NUM_ALPHA) * train_ds.captchalen\n",
    "    model = Model(OUTPUT_LEN = OUTPUT_LEN, TEMP_OUT = TEMP_OUT).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch [{epoch}]\")\n",
    "        model.train()\n",
    "        for image, ohlabel in train_dl:\n",
    "            image = image.to(device)\n",
    "            ohlabel = ohlabel.to(device,dtype=torch.float)\n",
    "            #label = torch.cuda.LongTensor(label)\n",
    "            \n",
    "            pred = model(image)\n",
    "            #print(pred.size())\n",
    "            #print(ohlabel.size())\n",
    "            loss = loss_fn(pred, ohlabel)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        sample_count = 0\n",
    "        correct_count = 0\n",
    "        model.eval()\n",
    "        for image, ohlabel in val_dl:\n",
    "            image = image.to(device)\n",
    "            ohlabel = ohlabel.to(device,dtype=torch.float)\n",
    "            \n",
    "            pred = model(image)\n",
    "            #print(pred.size())\n",
    "            #print(ohlabel.size())\n",
    "            loss = loss_fn(pred, ohlabel)\n",
    "            \n",
    "            #pred = torch.argmax(pred, dim=1)\n",
    "            \n",
    "\n",
    "            #print(torch.argmax(pred[:,0:36], dim=1))\n",
    "            #print(ohlabel)\n",
    "            same_i = [0]*task\n",
    "            for i in range(task):\n",
    "                pred_i = torch.argmax(pred[:,i*36:(i+1)*36], dim=1)\n",
    "                label = torch.argmax(ohlabel[:,i*36:(i+1)*36], dim=1)\n",
    "                same_i[i] = torch.eq(pred_i, label).type(torch.uint8)\n",
    "            result = same_i[0]\n",
    "            for i in range(1,task):\n",
    "                result = torch.logical_and(result, same_i[i]).type(torch.uint8)\n",
    "            #print(result)\n",
    "            sample_count += len(image)\n",
    "            #print(label.size())\n",
    "            #print(pred.size())\n",
    "            correct_count += result.sum()\n",
    "        val_acc = correct_count / sample_count\n",
    "        print(\"accuracy (validation):\", val_acc)\n",
    "        if best_acc <= val_acc:\n",
    "            best_acc = val_acc\n",
    "            PATH=f\"task{task}.pt\"\n",
    "            torch.save({\n",
    "                    'epoch': epoch+1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    }, PATH)\n",
    "    return PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "accuracy (validation): tensor(0.3022, device='cuda:0')\n",
      "Epoch [1]\n",
      "accuracy (validation): tensor(0.5961, device='cuda:0')\n",
      "Epoch [2]\n",
      "accuracy (validation): tensor(0.7303, device='cuda:0')\n",
      "Epoch [3]\n",
      "accuracy (validation): tensor(0.7382, device='cuda:0')\n",
      "Epoch [4]\n",
      "accuracy (validation): tensor(0.7732, device='cuda:0')\n",
      "Epoch [5]\n",
      "accuracy (validation): tensor(0.8140, device='cuda:0')\n",
      "Epoch [6]\n",
      "accuracy (validation): tensor(0.8224, device='cuda:0')\n",
      "Epoch [7]\n",
      "accuracy (validation): tensor(0.8272, device='cuda:0')\n",
      "Epoch [8]\n",
      "accuracy (validation): tensor(0.8557, device='cuda:0')\n",
      "Epoch [9]\n",
      "accuracy (validation): tensor(0.8390, device='cuda:0')\n",
      "Epoch [10]\n",
      "accuracy (validation): tensor(0.8399, device='cuda:0')\n",
      "Epoch [11]\n",
      "accuracy (validation): tensor(0.8632, device='cuda:0')\n",
      "Epoch [12]\n",
      "accuracy (validation): tensor(0.8614, device='cuda:0')\n",
      "Epoch [13]\n",
      "accuracy (validation): tensor(0.8724, device='cuda:0')\n",
      "Epoch [14]\n",
      "accuracy (validation): tensor(0.8566, device='cuda:0')\n",
      "Epoch [15]\n",
      "accuracy (validation): tensor(0.8789, device='cuda:0')\n",
      "Epoch [16]\n",
      "accuracy (validation): tensor(0.8776, device='cuda:0')\n",
      "Epoch [17]\n",
      "accuracy (validation): tensor(0.8746, device='cuda:0')\n",
      "Epoch [18]\n",
      "accuracy (validation): tensor(0.8825, device='cuda:0')\n",
      "Epoch [19]\n",
      "accuracy (validation): tensor(0.8890, device='cuda:0')\n",
      "Epoch [20]\n",
      "accuracy (validation): tensor(0.8636, device='cuda:0')\n",
      "Epoch [21]\n",
      "accuracy (validation): tensor(0.8908, device='cuda:0')\n",
      "Epoch [22]\n",
      "accuracy (validation): tensor(0.8873, device='cuda:0')\n",
      "Epoch [23]\n",
      "accuracy (validation): tensor(0.8833, device='cuda:0')\n",
      "Epoch [24]\n",
      "accuracy (validation): tensor(0.8991, device='cuda:0')\n",
      "Epoch [25]\n",
      "accuracy (validation): tensor(0.8934, device='cuda:0')\n",
      "Epoch [26]\n",
      "accuracy (validation): tensor(0.8961, device='cuda:0')\n",
      "Epoch [27]\n",
      "accuracy (validation): tensor(0.9057, device='cuda:0')\n",
      "Epoch [28]\n",
      "accuracy (validation): tensor(0.8851, device='cuda:0')\n",
      "Epoch [29]\n",
      "accuracy (validation): tensor(0.9044, device='cuda:0')\n",
      "Epoch [30]\n",
      "accuracy (validation): tensor(0.9026, device='cuda:0')\n",
      "Epoch [31]\n",
      "accuracy (validation): tensor(0.9066, device='cuda:0')\n",
      "Epoch [32]\n",
      "accuracy (validation): tensor(0.9083, device='cuda:0')\n",
      "Epoch [33]\n",
      "accuracy (validation): tensor(0.9105, device='cuda:0')\n",
      "Epoch [34]\n",
      "accuracy (validation): tensor(0.9092, device='cuda:0')\n",
      "Epoch [35]\n",
      "accuracy (validation): tensor(0.9022, device='cuda:0')\n",
      "Epoch [36]\n",
      "accuracy (validation): tensor(0.8987, device='cuda:0')\n",
      "Epoch [37]\n",
      "accuracy (validation): tensor(0.9154, device='cuda:0')\n",
      "Epoch [38]\n",
      "accuracy (validation): tensor(0.9088, device='cuda:0')\n",
      "Epoch [39]\n",
      "accuracy (validation): tensor(0.9101, device='cuda:0')\n",
      "Epoch [40]\n",
      "accuracy (validation): tensor(0.9175, device='cuda:0')\n",
      "Epoch [41]\n",
      "accuracy (validation): tensor(0.9189, device='cuda:0')\n",
      "Epoch [42]\n",
      "accuracy (validation): tensor(0.9158, device='cuda:0')\n",
      "Epoch [43]\n",
      "accuracy (validation): tensor(0.9145, device='cuda:0')\n",
      "Epoch [44]\n",
      "accuracy (validation): tensor(0.9149, device='cuda:0')\n",
      "Epoch [45]\n",
      "accuracy (validation): tensor(0.9145, device='cuda:0')\n",
      "Epoch [46]\n",
      "accuracy (validation): tensor(0.9145, device='cuda:0')\n",
      "Epoch [47]\n",
      "accuracy (validation): tensor(0.9219, device='cuda:0')\n",
      "Epoch [48]\n",
      "accuracy (validation): tensor(0.9237, device='cuda:0')\n",
      "Epoch [49]\n",
      "accuracy (validation): tensor(0.9145, device='cuda:0')\n",
      "Epoch [50]\n",
      "accuracy (validation): tensor(0.9180, device='cuda:0')\n",
      "Epoch [51]\n",
      "accuracy (validation): tensor(0.9263, device='cuda:0')\n",
      "Epoch [52]\n",
      "accuracy (validation): tensor(0.9193, device='cuda:0')\n",
      "Epoch [53]\n",
      "accuracy (validation): tensor(0.9259, device='cuda:0')\n",
      "Epoch [54]\n",
      "accuracy (validation): tensor(0.9298, device='cuda:0')\n",
      "Epoch [55]\n",
      "accuracy (validation): tensor(0.9237, device='cuda:0')\n",
      "Epoch [56]\n",
      "accuracy (validation): tensor(0.9241, device='cuda:0')\n",
      "Epoch [57]\n",
      "accuracy (validation): tensor(0.9333, device='cuda:0')\n",
      "Epoch [58]\n",
      "accuracy (validation): tensor(0.9316, device='cuda:0')\n",
      "Epoch [59]\n",
      "accuracy (validation): tensor(0.9224, device='cuda:0')\n",
      "Epoch [60]\n",
      "accuracy (validation): tensor(0.9272, device='cuda:0')\n",
      "Epoch [61]\n",
      "accuracy (validation): tensor(0.9272, device='cuda:0')\n",
      "Epoch [62]\n",
      "accuracy (validation): tensor(0.9311, device='cuda:0')\n",
      "Epoch [63]\n",
      "accuracy (validation): tensor(0.9276, device='cuda:0')\n",
      "Epoch [64]\n",
      "accuracy (validation): tensor(0.9360, device='cuda:0')\n",
      "Epoch [65]\n",
      "accuracy (validation): tensor(0.9285, device='cuda:0')\n",
      "Epoch [66]\n",
      "accuracy (validation): tensor(0.9408, device='cuda:0')\n",
      "Epoch [67]\n",
      "accuracy (validation): tensor(0.9333, device='cuda:0')\n",
      "Epoch [68]\n",
      "accuracy (validation): tensor(0.9386, device='cuda:0')\n",
      "Epoch [69]\n",
      "accuracy (validation): tensor(0.9368, device='cuda:0')\n",
      "Epoch [70]\n",
      "accuracy (validation): tensor(0.9364, device='cuda:0')\n",
      "Epoch [71]\n",
      "accuracy (validation): tensor(0.9382, device='cuda:0')\n",
      "Epoch [72]\n",
      "accuracy (validation): tensor(0.9404, device='cuda:0')\n",
      "Epoch [73]\n",
      "accuracy (validation): tensor(0.9386, device='cuda:0')\n",
      "Epoch [74]\n",
      "accuracy (validation): tensor(0.9434, device='cuda:0')\n",
      "Epoch [75]\n",
      "accuracy (validation): tensor(0.9342, device='cuda:0')\n",
      "Epoch [76]\n",
      "accuracy (validation): tensor(0.9399, device='cuda:0')\n",
      "Epoch [77]\n",
      "accuracy (validation): tensor(0.9399, device='cuda:0')\n",
      "Epoch [78]\n",
      "accuracy (validation): tensor(0.9355, device='cuda:0')\n",
      "Epoch [79]\n",
      "accuracy (validation): tensor(0.9368, device='cuda:0')\n",
      "Epoch [80]\n",
      "accuracy (validation): tensor(0.9351, device='cuda:0')\n",
      "Epoch [81]\n",
      "accuracy (validation): tensor(0.9408, device='cuda:0')\n",
      "Epoch [82]\n",
      "accuracy (validation): tensor(0.9382, device='cuda:0')\n",
      "Epoch [83]\n",
      "accuracy (validation): tensor(0.9395, device='cuda:0')\n",
      "Epoch [84]\n",
      "accuracy (validation): tensor(0.9439, device='cuda:0')\n",
      "Epoch [85]\n",
      "accuracy (validation): tensor(0.9447, device='cuda:0')\n",
      "Epoch [86]\n",
      "accuracy (validation): tensor(0.9408, device='cuda:0')\n",
      "Epoch [87]\n",
      "accuracy (validation): tensor(0.9382, device='cuda:0')\n",
      "Epoch [88]\n",
      "accuracy (validation): tensor(0.9377, device='cuda:0')\n",
      "Epoch [89]\n",
      "accuracy (validation): tensor(0.9421, device='cuda:0')\n",
      "Epoch [90]\n",
      "accuracy (validation): tensor(0.9382, device='cuda:0')\n",
      "Epoch [91]\n",
      "accuracy (validation): tensor(0.9434, device='cuda:0')\n",
      "Epoch [92]\n",
      "accuracy (validation): tensor(0.9333, device='cuda:0')\n",
      "Epoch [93]\n",
      "accuracy (validation): tensor(0.9368, device='cuda:0')\n",
      "Epoch [94]\n",
      "accuracy (validation): tensor(0.9368, device='cuda:0')\n",
      "Epoch [95]\n",
      "accuracy (validation): tensor(0.9386, device='cuda:0')\n",
      "Epoch [96]\n",
      "accuracy (validation): tensor(0.9430, device='cuda:0')\n",
      "Epoch [97]\n",
      "accuracy (validation): tensor(0.9408, device='cuda:0')\n",
      "Epoch [98]\n",
      "accuracy (validation): tensor(0.9373, device='cuda:0')\n",
      "Epoch [99]\n",
      "accuracy (validation): tensor(0.9303, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "Path1 = train(train_dl, val_dl, train_ds, epochs=30, TEMP_OUT=4096)\n",
    "Path2 = train(train2_dl, val2_dl, train2_ds, epochs=100, TEMP_OUT=4096)\n",
    "Path3 = train(train3_dl, val3_dl, train3_ds, epochs=120, TEMP_OUT=7168)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10 (default, Feb 26 2021, 13:06:18) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab78bb3c465f8a9a3b2b3033a0b53f8ddb3d4f2700280c40496e40ae689e591d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
